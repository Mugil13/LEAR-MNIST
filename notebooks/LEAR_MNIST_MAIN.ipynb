{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Configuration and Hyperparameters\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "mode = 1  # Set to 0 for Learn, 1 for Explain\n",
        "save_path = \"./lear_results/\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Hyperparameters (from original M_config)\n",
        "disc_ch = cfmap_ch = 32\n",
        "num_epochs = 100\n",
        "batch_size = 256\n",
        "if mode == 0:\n",
        "    lr = 0.0005\n",
        "    lr_decay = 0.98\n",
        "else:\n",
        "    g_step, d_step = 1, 1\n",
        "    lr_g, lr_d = 0.001, 0.001\n",
        "    lr_decay = 0.99\n",
        "    beta1 = 0.9\n",
        "    one_sided_label_smoothing = 0.1\n",
        "\n",
        "# Loss weights (lambda values from hyper_param list in M_config)\n",
        "loss_weights = {'cls': 1.0, 'norm': 10.0, 'GAN': 1.0, 'cyc': 1.0, 'dis': 0.5}"
      ],
      "metadata": {
        "id": "2QAOQYON7t36"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads MNIST data as NumPy arrays.\"\"\"\n",
        "    train = datasets.MNIST(root=\".\", train=True, download=True)\n",
        "    test  = datasets.MNIST(root=\".\", train=False, download=True)\n",
        "    images_train = train.data.numpy().astype(np.float32)  # shape (60000,28,28)\n",
        "    labels_train = train.targets.numpy().astype(np.int64) # shape (60000,)\n",
        "    images_test  = test.data.numpy().astype(np.float32)   # shape (10000,28,28)\n",
        "    labels_test  = test.targets.numpy().astype(np.int64)\n",
        "    return images_train, labels_train, images_test, labels_test\n",
        "\n",
        "def create_splits(labels_train, labels_test):\n",
        "    \"\"\"Creates train/val/test index splits using a fixed seed.\"\"\"\n",
        "    rng = np.random.RandomState(seed=970304)\n",
        "    all_idx = rng.permutation(np.where(labels_train >= 0)[0])\n",
        "    n_val = int(len(all_idx) * 0.1)\n",
        "    valid_idx = all_idx[:n_val]\n",
        "    train_idx = all_idx[n_val:]\n",
        "    test_idx = rng.permutation(np.where(labels_test >= 0)[0])\n",
        "    return train_idx, valid_idx, test_idx\n",
        "\n",
        "def separate_data(idx, all_dat, all_lbl, center=True):\n",
        "    \"\"\"\n",
        "    Selects a batch by indices and preprocesses:\n",
        "      - center=True: normalize each image to [0,1].\n",
        "      - center=False: pad 2 pixels, random crop back to 28x28, then normalize.\n",
        "    Returns (batch,1,28,28) images and (batch,10) one-hot labels.\n",
        "    \"\"\"\n",
        "    batch_size = len(idx)\n",
        "    dat = all_dat[idx]  # shape (batch,28,28)\n",
        "    if not center:\n",
        "        # Pad and random crop\n",
        "        padded = np.pad(dat, ((0,0),(2,2),(2,2)), mode='constant')  # to 32x32\n",
        "        cropped = np.empty((batch_size,28,28), dtype=np.float32)\n",
        "        for i in range(batch_size):\n",
        "            h_off = np.random.randint(0, 5)\n",
        "            w_off = np.random.randint(0, 5)\n",
        "            cropped[i] = padded[i, h_off:h_off+28, w_off:w_off+28]\n",
        "        dat = cropped\n",
        "    # Per-image normalization to [0,1]\n",
        "    for i in range(batch_size):\n",
        "        img = dat[i]\n",
        "        img_min = img.min()\n",
        "        img_max = img.max()\n",
        "        if img_max > img_min:\n",
        "            dat[i] = (img - img_min) / (img_max - img_min)\n",
        "        else:\n",
        "            dat[i] = img  # constant image\n",
        "    dat = np.expand_dims(dat, axis=1)  # to (batch,1,28,28)\n",
        "    # One-hot encode labels\n",
        "    lbl = all_lbl[idx]\n",
        "    lbl_onehot = np.eye(10)[lbl]\n",
        "    lbl_onehot = lbl_onehot.astype(np.float32)\n",
        "    return dat.astype(np.float32), lbl_onehot\n",
        "\n",
        "def code_creator(size):\n",
        "    \"\"\"Generates random target one-hot codes for each sample in a batch.\"\"\"\n",
        "    target_c = np.zeros((size,10), dtype=np.float32)\n",
        "    for i in range(size):\n",
        "        c = np.random.randint(0, 10)  # pick random class\n",
        "        target_c[i, c] = 1.0\n",
        "    return target_c\n",
        "\n",
        "# Update ipython-input-22-47982226\n",
        "def codemap(target_c):\n",
        "    \"\"\"\n",
        "    Converts target class vectors into spatial code maps c1 (14x14), c2 (7x7), c3 (4x4).\n",
        "    Each map has 10 channels: for class k, the (h,w) entries are target_c[:,k].\n",
        "    \"\"\"\n",
        "    batch = target_c.shape[0]\n",
        "    c1 = np.zeros((batch, 10, 14, 14), dtype=np.float32)\n",
        "    c2 = np.zeros((batch, 10, 7, 7), dtype=np.float32)\n",
        "    # c3 size should be 4x4 to match the encoder's conv3_2 output after correction\n",
        "    c3 = np.zeros((batch, 10, 4, 4), dtype=np.float32)\n",
        "    for b in range(batch):\n",
        "        for k in range(10):\n",
        "            if target_c[b, k] != 0:\n",
        "                c1[b, k, :, :] = target_c[b, k]\n",
        "                c2[b, k, :, :] = target_c[b, k]\n",
        "                c3[b, k, :, :] = target_c[b, k]\n",
        "    return c1, c2, c3"
      ],
      "metadata": {
        "id": "mTw5grMO7uxI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update ipython-input-23-47982226\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, ch=32):\n",
        "        super().__init__()\n",
        "        # conv1 block (28x28 -> 14x14)\n",
        "        self.conv1_1 = nn.Conv2d(1,   ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1_1   = nn.BatchNorm2d(ch)\n",
        "        self.conv1_2 = nn.Conv2d(ch,  ch, kernel_size=4, stride=2, padding=1)  # 28->14\n",
        "        self.bn1_2   = nn.BatchNorm2d(ch)\n",
        "        # conv2 block (14x14 -> 7x7)\n",
        "        self.conv2_1 = nn.Conv2d(ch,  ch*2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_1   = nn.BatchNorm2d(ch*2)\n",
        "        self.conv2_2 = nn.Conv2d(ch*2, ch*2, kernel_size=4, stride=2, padding=1)  # 14->7\n",
        "        self.bn2_2   = nn.BatchNorm2d(ch*2)\n",
        "        # conv3 block (7x7 -> 4x4) - Changed kernel size and padding to achieve 4x4 output\n",
        "        self.conv3_1 = nn.Conv2d(ch*2, ch*4, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_1   = nn.BatchNorm2d(ch*4)\n",
        "        # (7 - kernel_size + 2*padding)/stride + 1 = (7 - 3 + 2*1)/2 + 1 = 4x4\n",
        "        self.conv3_2 = nn.Conv2d(ch*4, ch*4, kernel_size=3, stride=2, padding=1)  # 7->4 # Corrected\n",
        "        self.bn3_2   = nn.BatchNorm2d(ch*4)\n",
        "        # conv4 block (4x4 -> 2x2) - Now takes 4x4 input and correctly outputs 2x2\n",
        "        self.conv4_1 = nn.Conv2d(ch*4, ch*8, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_1   = nn.BatchNorm2d(ch*8)\n",
        "        # (4 - kernel_size + 2*padding)/stride + 1 = (4 - 4 + 2*1)/2 + 1 = 2x2\n",
        "        self.conv4_2 = nn.Conv2d(ch*8, ch*8, kernel_size=4, stride=2, padding=1)  # 4->2 # Corrected\n",
        "        self.bn4_2   = nn.BatchNorm2d(ch*8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
        "        conv1_2 = x  # size [B, ch, 14,14]\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
        "        conv2_2 = x  # [B, 2ch, 7,7]\n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
        "        conv3_2 = x  # [B, 4ch, 4,4] # This comment is now correct with the change\n",
        "        x = F.relu(self.bn4_1(self.conv4_1(x)))\n",
        "        x = F.relu(self.bn4_2(self.conv4_2(x)))\n",
        "        conv4_2 = x  # [B, 8ch, 2,2] # This comment is now correct\n",
        "        return conv1_2, conv2_2, conv3_2, conv4_2\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, ch=32):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(ch)\n",
        "        # Two fully-connected layers with dropouts\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        # Corrected input size to FC layer: flattened size of [B, 8ch, 2, 2] is B * 8ch * 2 * 2 = B * 32ch\n",
        "        self.fc1 = nn.Linear(ch * 8 * 4, 128) # Adjusted input size to FC layer\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "        self.fc2      = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B,1,28,28]\n",
        "        _, _, _, enc_out = self.encoder(x)      # enc_out [B,8ch,2,2] # This comment is now correct\n",
        "        # Flatten [B, 8ch, 2, 2] to [B, 8ch * 4]\n",
        "        flat = enc_out.view(x.size(0), -1)      # [B, 8ch*4] # This comment is now correct\n",
        "        x = self.dropout1(flat)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)                         # [B,10] logits\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, ch=32):\n",
        "        super().__init__()\n",
        "        # Upsampling (bilinear) layers\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        # dec_upconv3: from enc_conv4_2 upsample (2x2 -> 4x4) # This is correct now\n",
        "        self.dec_upconv3 = nn.Conv2d(ch*8, ch*4, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_upconv3  = nn.BatchNorm2d(ch*4)\n",
        "        # dec_code_conv3: after concatenating with c3 (size [4ch+10,4,4]) # This is correct now\n",
        "        self.dec_code_conv3 = nn.Conv2d(ch*4 + 10, ch*4, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_code_conv3  = nn.BatchNorm2d(ch*4)\n",
        "        # dec_conv3: after merging skip and up paths (size [8ch,4,4]) # This is correct now\n",
        "        self.dec_conv3 = nn.Conv2d(ch*8, ch*4, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_conv3  = nn.BatchNorm2d(ch*4)\n",
        "        # dec_upconv2: (4x4 -> 8x8 -> 7x7 after valid conv)\n",
        "        # Input is 4x4. Upsample by 2 -> 8x8.\n",
        "        # dec_upconv2: kernel_size=2, stride=1, padding=0. Output: (8-2+0)/1 + 1 = 6+1 = 7x7. OK.\n",
        "        self.dec_upconv2 = nn.Conv2d(ch*4, ch*2, kernel_size=2, stride=1, padding=0)  # 8->7 # Corrected comment\n",
        "        self.bn_upconv2  = nn.BatchNorm2d(ch*2)\n",
        "        # dec_code_conv2: cat with c2 (size [2ch+10,7,7]). OK\n",
        "        self.dec_code_conv2 = nn.Conv2d(ch*2 + 10, ch*2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_code_conv2  = nn.BatchNorm2d(ch*2)\n",
        "        # dec_conv2: after merging (size [4ch,7,7]). OK.\n",
        "        self.dec_conv2 = nn.Conv2d(ch*4, ch*2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_conv2  = nn.BatchNorm2d(ch*2)\n",
        "        # dec_upconv1: (7x7 -> 14x14)\n",
        "        self.dec_upconv1 = nn.Conv2d(ch*2, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_upconv1  = nn.BatchNorm2d(ch)\n",
        "        # dec_code_conv1: cat with c1 (size [ch+10,14,14]). OK.\n",
        "        self.dec_code_conv1 = nn.Conv2d(ch + 10, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_code_conv1  = nn.BatchNorm2d(ch)\n",
        "        # dec_conv1: after merging (size [2ch,14,14]). OK.\n",
        "        self.dec_conv1 = nn.Conv2d(ch*2, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn_conv1  = nn.BatchNorm2d(ch)\n",
        "        # Final upsampling via ConvTranspose2d (14->28)\n",
        "        # Input: 14x14. Output: (14-1)*2 - 2*1 + 4 = 13*2 - 2 + 4 = 26 - 2 + 4 = 28x28. OK.\n",
        "        self.dec_up = nn.ConvTranspose2d(ch, 1, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, enc1, enc2, enc3, enc4, c1, c2, c3):\n",
        "        \"\"\"\n",
        "        enc1: conv1_2 (B, ch,14,14)\n",
        "        enc2: conv2_2 (B,2ch,7,7)\n",
        "        enc3: conv3_2 (B,4ch,4,4) # Corrected comment\n",
        "        enc4: conv4_2 (B,8ch,2,2) # Corrected comment\n",
        "        c1: [B,10,14,14]; c2: [B,10,7,7]; c3: [B,10,4,4] # This comment should match the code after fixing codemap\n",
        "        \"\"\"\n",
        "        # Stage 3\n",
        "        x = self.upsample(enc4)                          # (2x2 -> 4x4)\n",
        "        x = F.relu(self.bn_upconv3(self.dec_upconv3(x))) # (B,4ch,4,4)\n",
        "        # We changed enc3 to be 4x4 by modifying the encoder, and adjusted c3 to be 4x4 by modifying codemap.\n",
        "        # So concatenation [enc3 (B,4ch,4,4), c3 (B,10,4,4)] along dim=1 should work now.\n",
        "        cat3 = torch.cat([enc3, c3], dim=1)             # (B,4ch+10,4,4) # This line is now correct\n",
        "        y = F.relu(self.bn_code_conv3(self.dec_code_conv3(cat3)))  # (B,4ch,4,4)\n",
        "        z = torch.cat([y, x], dim=1)                    # (B,8ch,4,4)\n",
        "        dec3 = F.relu(self.bn_conv3(self.dec_conv3(z))) # (B,4ch,4,4)\n",
        "        # Stage 2\n",
        "        x = self.upsample(dec3)                         # (4x4 -> 8x8)\n",
        "        x = F.relu(self.bn_upconv2(self.dec_upconv2(x)))# (B,2ch,7,7) # Corrected comment\n",
        "        cat2 = torch.cat([enc2, c2], dim=1)             # (B,2ch+10,7,7)\n",
        "        y = F.relu(self.bn_code_conv2(self.dec_code_conv2(cat2)))  # (B,2ch,7,7)\n",
        "        z = torch.cat([y, x], dim=1)                    # (B,4ch,7,7)\n",
        "        dec2 = F.relu(self.bn_conv2(self.dec_conv2(z))) # (B,2ch,7,7)\n",
        "        # Stage 1\n",
        "        x = self.upsample(dec2)                         # (7x7 -> 14x14)\n",
        "        x = F.relu(self.bn_upconv1(self.dec_upconv1(x)))# (B,ch,14,14)\n",
        "        cat1 = torch.cat([enc1, c1], dim=1)             # (B,ch+10,14,14)\n",
        "        y = F.relu(self.bn_code_conv1(self.dec_code_conv1(cat1)))  # (B,ch,14,14)\n",
        "        z = torch.cat([y, x], dim=1)                    # (B,2ch,14,14)\n",
        "        dec1 = F.relu(self.bn_conv1(self.dec_conv1(z))) # (B,ch,14,14)\n",
        "        # Final upsampling\n",
        "        out = self.dec_up(dec1)  # (B,1,28,28)\n",
        "        out = torch.tanh(out)    # counterfactual map in [-1,1]\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ch=32):\n",
        "        super().__init__()\n",
        "        # conv1 (28x28)\n",
        "        self.conv1_1 = nn.Conv2d(1, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(ch, ch, kernel_size=4, stride=2, padding=1)  # 28->14\n",
        "        self.bn1_2   = nn.BatchNorm2d(ch)\n",
        "        # conv2 (14x14)\n",
        "        self.conv2_1 = nn.Conv2d(ch, ch*2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_1   = nn.BatchNorm2d(ch*2)\n",
        "        self.conv2_2 = nn.Conv2d(ch*2, ch*2, kernel_size=4, stride=2, padding=1)  # 14->7\n",
        "        self.bn2_2   = nn.BatchNorm2d(ch*2)\n",
        "        # conv3 (7x7)\n",
        "        self.conv3_1 = nn.Conv2d(ch*2, ch*4, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_1   = nn.BatchNorm2d(ch*4)\n",
        "        self.conv3_2 = nn.Conv2d(ch*4, ch*4, kernel_size=4, stride=2, padding=1)  # 7->4\n",
        "        self.bn3_2   = nn.BatchNorm2d(ch*4)\n",
        "        # conv4 (4x4)\n",
        "        self.conv4_1 = nn.Conv2d(ch*4, ch*8, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_1   = nn.BatchNorm2d(ch*8)\n",
        "        self.conv4_2 = nn.Conv2d(ch*8, ch*8, kernel_size=4, stride=2, padding=1)  # 4->2\n",
        "        # Output layer\n",
        "        self.fc      = nn.Linear(ch*8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.conv1_2(x);  x = self.bn1_2(x); x = F.leaky_relu(x, 0.2)\n",
        "        x = self.conv2_1(x);  x = self.bn2_1(x); x = F.leaky_relu(x, 0.2)\n",
        "        x = self.conv2_2(x);  x = self.bn2_2(x); x = F.leaky_relu(x, 0.2)\n",
        "        x = self.conv3_1(x);  x = self.bn3_1(x); x = F.leaky_relu(x, 0.2)\n",
        "        x = self.conv3_2(x);  x = self.bn3_2(x); x = F.leaky_relu(x, 0.2)\n",
        "        x = self.conv4_1(x);  x = self.bn4_1(x); x = F.leaky_relu(x, 0.2)\n",
        "        x = self.conv4_2(x)   # [B, ch*8, 2,2]\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)        # [B, 1] raw logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "An1Lwugz718V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss objects\n",
        "ce_loss_fn = nn.CrossEntropyLoss()\n",
        "mse_loss   = nn.MSELoss()\n",
        "l1_loss    = nn.L1Loss()\n",
        "\n",
        "def classification_accuracy(logits, labels_idx):\n",
        "    \"\"\"Compute accuracy given logits and true class indices.\"\"\"\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    return (preds == labels_idx).float().mean().item()\n",
        "\n",
        "def one_sided_smooth(target_onehot):\n",
        "    \"\"\"Apply one-sided label smoothing (1->0.9, 0->0) for one-hot vectors.\"\"\"\n",
        "    # Convert numpy to torch if needed\n",
        "    # target_onehot is a float tensor [B,10]\n",
        "    return torch.where(target_onehot == 1.0, 0.9, target_onehot)"
      ],
      "metadata": {
        "id": "fhv3etkR72bh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if mode == 0:\n",
        "    # Load data and create splits\n",
        "    images_train, labels_train, images_test, labels_test = load_data()\n",
        "    train_idx, valid_idx, test_idx = create_splits(labels_train, labels_test)\n",
        "\n",
        "    # Initialize model, optimizer, scheduler\n",
        "    model = Classifier(ch=cfmap_ch).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        np.random.shuffle(train_idx)\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        # --- Training ---\n",
        "        for i in range(0, len(train_idx), batch_size):\n",
        "            batch_idx = train_idx[i:i+batch_size]\n",
        "            batch_x, batch_y = separate_data(batch_idx, images_train, labels_train, center=False)\n",
        "            inputs = torch.tensor(batch_x).to(device)          # [B,1,28,28]\n",
        "            labels_onehot = torch.tensor(batch_y).to(device)\n",
        "            labels_idx = torch.tensor(labels_train[batch_idx]).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(inputs)     # [B,10]\n",
        "            loss = ce_loss_fn(logits, labels_idx)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        scheduler.step()  # decay LR\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0; val_acc = 0.0; count = 0\n",
        "            for i in range(0, len(valid_idx), batch_size):\n",
        "                val_batch = valid_idx[i:i+batch_size]\n",
        "                vx, vy = separate_data(val_batch, images_train, labels_train, center=True)\n",
        "                vx = torch.tensor(vx).to(device)\n",
        "                vy_idx = torch.tensor(labels_train[val_batch]).to(device)\n",
        "                logits = model(vx)\n",
        "                loss = ce_loss_fn(logits, vy_idx)\n",
        "                acc = classification_accuracy(logits, vy_idx)\n",
        "                val_loss += loss.item()\n",
        "                val_acc  += acc\n",
        "                count += 1\n",
        "            val_loss /= count\n",
        "            val_acc  /= count\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss={running_loss/len(train_idx):.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "            # Save best model by validation accuracy\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(model.state_dict(), os.path.join(save_path, f\"cls_model_best.pth\"))\n",
        "\n",
        "        # --- Test Evaluation ---\n",
        "        test_loss = 0.0; test_acc = 0.0; tcount = 0\n",
        "        for i in range(0, len(test_idx), batch_size):\n",
        "            test_batch = test_idx[i:i+batch_size]\n",
        "            tx, ty = separate_data(test_batch, images_test, labels_test, center=True)\n",
        "            tx = torch.tensor(tx).to(device)\n",
        "            ty_idx = torch.tensor(labels_test[test_batch]).to(device)\n",
        "            logits = model(tx)\n",
        "            loss = ce_loss_fn(logits, ty_idx)\n",
        "            acc = classification_accuracy(logits, ty_idx)\n",
        "            test_loss += loss.item()\n",
        "            test_acc  += acc\n",
        "            tcount += 1\n",
        "        test_loss /= tcount\n",
        "        test_acc  /= tcount\n",
        "        print(f\"Epoch {epoch+1}: Test Loss={test_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
        "\n",
        "    # Save final models (encoder + classifier)\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, \"cls_model_final.pth\"))\n",
        "    torch.save(model.encoder.state_dict(), os.path.join(save_path, \"enc_model_final.pth\"))\n",
        "\n",
        "elif mode == 1:\n",
        "    # Load data and splits (re-use indices from mode0 or recompute)\n",
        "    images_train, labels_train, images_test, labels_test = load_data()\n",
        "    train_idx, valid_idx, test_idx = create_splits(labels_train, labels_test)\n",
        "\n",
        "    # Initialize models\n",
        "    classifier = Classifier(ch=cfmap_ch).to(device)\n",
        "    classifier.load_state_dict(torch.load(os.path.join(save_path, \"cls_model_best.pth\")))\n",
        "    for param in classifier.parameters():\n",
        "        param.requires_grad = False  # freeze classifier\n",
        "    decoder = Decoder(ch=cfmap_ch).to(device)\n",
        "    discriminator = Discriminator(ch=disc_ch).to(device)\n",
        "\n",
        "    # Separate encoder for obtaining features\n",
        "    encoder = classifier.encoder\n",
        "\n",
        "    # Optimizers and schedulers\n",
        "    gen_params = list(decoder.parameters())\n",
        "    disc_params = list(discriminator.parameters())\n",
        "    gen_opt = optim.Adam(gen_params, lr=lr_g, betas=(beta1, 0.999))\n",
        "    disc_opt = optim.Adam(disc_params, lr=lr_d, betas=(beta1, 0.999))\n",
        "    gen_scheduler = optim.lr_scheduler.ExponentialLR(gen_opt, gamma=lr_decay)\n",
        "    disc_scheduler = optim.lr_scheduler.ExponentialLR(disc_opt, gamma=lr_decay)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        np.random.shuffle(train_idx)\n",
        "        # Training\n",
        "        decoder.train(); discriminator.train()\n",
        "        for step in range(0, len(train_idx), batch_size):\n",
        "            batch_idx = train_idx[step:step+batch_size]\n",
        "            batch_x, batch_y = separate_data(batch_idx, images_train, labels_train, center=False)\n",
        "            inputs = torch.tensor(batch_x).to(device)           # [B,1,28,28]\n",
        "            labels_onehot = torch.tensor(batch_y).to(device)   # [B,10]\n",
        "            labels_idx = torch.tensor(labels_train[batch_idx]).to(device)\n",
        "\n",
        "            # Prepare target class codes for generator\n",
        "            target_c = torch.tensor(code_creator(len(batch_idx)), dtype=torch.float32).to(device)\n",
        "\n",
        "            # === Discriminator step ===\n",
        "            # Generate CF-map and pseudo-images\n",
        "            with torch.no_grad():\n",
        "                enc1, enc2, enc3, enc4 = encoder(inputs)  # get encoder features\n",
        "                c1_np, c2_np, c3_np = codemap(target_c.cpu().numpy())\n",
        "                c1 = torch.tensor(c1_np).to(device)\n",
        "                c2 = torch.tensor(c2_np).to(device)\n",
        "                c3 = torch.tensor(c3_np).to(device)\n",
        "                CFmap = decoder(enc1, enc2, enc3, enc4, c1, c2, c3)\n",
        "                pseudo = inputs + CFmap\n",
        "\n",
        "            real_logits = discriminator(inputs)\n",
        "            fake_logits = discriminator(pseudo)\n",
        "            # Real labels=1, Fake labels=0\n",
        "            d_loss_real = mse_loss(real_logits, torch.ones_like(real_logits))\n",
        "            d_loss_fake = mse_loss(fake_logits, torch.zeros_like(fake_logits))\n",
        "            d_loss = loss_weights['dis'] * (d_loss_real + d_loss_fake)\n",
        "\n",
        "            disc_opt.zero_grad()\n",
        "            d_loss.backward()\n",
        "            disc_opt.step()\n",
        "\n",
        "            # === Generator (Decoder) step ===\n",
        "            # Recompute CF-map (now with grad) and pseudo\n",
        "            enc1, enc2, enc3, enc4 = encoder(inputs)\n",
        "            CFmap = decoder(enc1, enc2, enc3, enc4, c1, c2, c3)\n",
        "            pseudo = inputs + CFmap\n",
        "\n",
        "            # Classification output on pseudo-images\n",
        "            logits_fake = classifier(pseudo)\n",
        "            # Optionally apply one-sided smoothing to target codes\n",
        "            if one_sided_label_smoothing:\n",
        "                smoothed = one_sided_smooth(target_c)\n",
        "                cls_loss = loss_weights['cls'] * torch.mean(-torch.sum(smoothed.to(device) * F.log_softmax(logits_fake, dim=1), dim=1))\n",
        "            else:\n",
        "                # direct CE with integer targets\n",
        "                cls_loss = loss_weights['cls'] * ce_loss_fn(logits_fake, torch.tensor(np.argmax(target_c.cpu().numpy(), axis=1)).to(device))\n",
        "\n",
        "            # GAN loss (generator tries to make discriminator output 1)\n",
        "            gan_loss = loss_weights['GAN'] * mse_loss(discriminator(pseudo), torch.ones_like(fake_logits))\n",
        "\n",
        "            # Cycle-consistency: feed pseudo back into decoder using predicted label\n",
        "            with torch.no_grad():\n",
        "                pred_probs = F.softmax(logits_fake, dim=1)\n",
        "            c1_pred_np, c2_pred_np, c3_pred_np = codemap(pred_probs.cpu().numpy())\n",
        "            c1_pred = torch.tensor(c1_pred_np).to(device)\n",
        "            c2_pred = torch.tensor(c2_pred_np).to(device)\n",
        "            c3_pred = torch.tensor(c3_pred_np).to(device)\n",
        "            enc1_p, enc2_p, enc3_p, enc4_p = encoder(pseudo)\n",
        "            tilde_map = decoder(enc1_p, enc2_p, enc3_p, enc4_p, c1_pred, c2_pred, c3_pred)\n",
        "            like_input = pseudo + tilde_map\n",
        "            cyc_loss = loss_weights['cyc'] * torch.mean(torch.abs(like_input - inputs))\n",
        "\n",
        "            # L1 norm on CF-map (sparsity/regularization)\n",
        "            l1_norm_loss = loss_weights['norm'] * torch.mean(torch.abs(CFmap))\n",
        "\n",
        "            # Total generator loss\n",
        "            g_loss = cls_loss + gan_loss + cyc_loss + l1_norm_loss\n",
        "\n",
        "            gen_opt.zero_grad()\n",
        "            g_loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "        gen_scheduler.step()\n",
        "        disc_scheduler.step()\n",
        "\n",
        "        # Validation printout (accuracy of classifier on reconstruction)\n",
        "        decoder.eval()\n",
        "        total_tst_acc = 0.0\n",
        "        batches = 0\n",
        "        with torch.no_grad():\n",
        "            for step in range(0, len(test_idx), batch_size):\n",
        "                batch_idx = test_idx[step:step+batch_size]\n",
        "                tx, ty = separate_data(batch_idx, images_test, labels_test, center=True)\n",
        "                tx = torch.tensor(tx).to(device)\n",
        "                ty_idx = torch.tensor(labels_test[batch_idx]).to(device)\n",
        "                # Generate pseudo images targeting random classes (or use code_creator)\n",
        "                target_c = torch.tensor(code_creator(len(batch_idx)), dtype=torch.float32).to(device)\n",
        "                enc1, enc2, enc3, enc4 = encoder(tx)\n",
        "                c1_np, c2_np, c3_np = codemap(target_c.cpu().numpy())\n",
        "                c1 = torch.tensor(c1_np).to(device)\n",
        "                c2 = torch.tensor(c2_np).to(device)\n",
        "                c3 = torch.tensor(c3_np).to(device)\n",
        "                CFmap = decoder(enc1, enc2, enc3, enc4, c1, c2, c3)\n",
        "                pseudo = tx + CFmap\n",
        "                pred = classifier(pseudo)\n",
        "                # Compare predicted class to the target code's class\n",
        "                target_idx = torch.tensor(np.argmax(target_c.cpu().numpy(), axis=1)).to(device)\n",
        "                acc = classification_accuracy(pred, target_idx)\n",
        "                total_tst_acc += acc\n",
        "                batches += 1\n",
        "            avg_tst_acc = total_tst_acc / batches\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs} (Explain): Test Acc (pseudo vs target) = {avg_tst_acc:.4f}\")\n",
        "\n",
        "    # Save final decoder model\n",
        "    torch.save(decoder.state_dict(), os.path.join(save_path, \"dec_model_final.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVf4WRJ477N4",
        "outputId": "e3a96c82-bd66-460e-b05e-c1575a47a0d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 (Explain): Test Acc (pseudo vs target) = 0.9826\n",
            "Epoch 2/100 (Explain): Test Acc (pseudo vs target) = 0.9607\n",
            "Epoch 3/100 (Explain): Test Acc (pseudo vs target) = 0.9866\n",
            "Epoch 4/100 (Explain): Test Acc (pseudo vs target) = 0.9462\n",
            "Epoch 5/100 (Explain): Test Acc (pseudo vs target) = 0.9818\n",
            "Epoch 6/100 (Explain): Test Acc (pseudo vs target) = 0.9545\n",
            "Epoch 7/100 (Explain): Test Acc (pseudo vs target) = 0.9591\n",
            "Epoch 8/100 (Explain): Test Acc (pseudo vs target) = 0.9794\n",
            "Epoch 9/100 (Explain): Test Acc (pseudo vs target) = 0.9844\n",
            "Epoch 10/100 (Explain): Test Acc (pseudo vs target) = 0.9871\n",
            "Epoch 11/100 (Explain): Test Acc (pseudo vs target) = 0.9896\n",
            "Epoch 12/100 (Explain): Test Acc (pseudo vs target) = 0.9849\n",
            "Epoch 13/100 (Explain): Test Acc (pseudo vs target) = 0.9953\n",
            "Epoch 14/100 (Explain): Test Acc (pseudo vs target) = 0.9851\n",
            "Epoch 15/100 (Explain): Test Acc (pseudo vs target) = 0.9821\n",
            "Epoch 16/100 (Explain): Test Acc (pseudo vs target) = 0.9958\n",
            "Epoch 17/100 (Explain): Test Acc (pseudo vs target) = 0.9976\n",
            "Epoch 18/100 (Explain): Test Acc (pseudo vs target) = 0.9965\n",
            "Epoch 19/100 (Explain): Test Acc (pseudo vs target) = 0.9361\n",
            "Epoch 20/100 (Explain): Test Acc (pseudo vs target) = 0.9611\n",
            "Epoch 21/100 (Explain): Test Acc (pseudo vs target) = 0.9764\n",
            "Epoch 22/100 (Explain): Test Acc (pseudo vs target) = 0.9714\n",
            "Epoch 23/100 (Explain): Test Acc (pseudo vs target) = 0.9715\n",
            "Epoch 24/100 (Explain): Test Acc (pseudo vs target) = 0.9907\n",
            "Epoch 25/100 (Explain): Test Acc (pseudo vs target) = 0.9741\n",
            "Epoch 26/100 (Explain): Test Acc (pseudo vs target) = 0.9793\n",
            "Epoch 27/100 (Explain): Test Acc (pseudo vs target) = 0.9671\n",
            "Epoch 28/100 (Explain): Test Acc (pseudo vs target) = 0.9662\n",
            "Epoch 29/100 (Explain): Test Acc (pseudo vs target) = 0.9758\n",
            "Epoch 30/100 (Explain): Test Acc (pseudo vs target) = 0.9493\n",
            "Epoch 31/100 (Explain): Test Acc (pseudo vs target) = 0.9654\n",
            "Epoch 32/100 (Explain): Test Acc (pseudo vs target) = 0.9620\n",
            "Epoch 33/100 (Explain): Test Acc (pseudo vs target) = 0.9050\n",
            "Epoch 34/100 (Explain): Test Acc (pseudo vs target) = 0.9637\n",
            "Epoch 35/100 (Explain): Test Acc (pseudo vs target) = 0.9475\n",
            "Epoch 36/100 (Explain): Test Acc (pseudo vs target) = 0.8495\n",
            "Epoch 37/100 (Explain): Test Acc (pseudo vs target) = 0.9021\n",
            "Epoch 38/100 (Explain): Test Acc (pseudo vs target) = 0.9961\n",
            "Epoch 39/100 (Explain): Test Acc (pseudo vs target) = 0.9006\n",
            "Epoch 40/100 (Explain): Test Acc (pseudo vs target) = 0.9143\n",
            "Epoch 41/100 (Explain): Test Acc (pseudo vs target) = 0.9735\n",
            "Epoch 42/100 (Explain): Test Acc (pseudo vs target) = 0.8257\n",
            "Epoch 43/100 (Explain): Test Acc (pseudo vs target) = 0.9321\n",
            "Epoch 44/100 (Explain): Test Acc (pseudo vs target) = 0.9666\n",
            "Epoch 45/100 (Explain): Test Acc (pseudo vs target) = 0.9688\n",
            "Epoch 46/100 (Explain): Test Acc (pseudo vs target) = 0.9409\n",
            "Epoch 47/100 (Explain): Test Acc (pseudo vs target) = 0.9926\n",
            "Epoch 48/100 (Explain): Test Acc (pseudo vs target) = 0.9690\n",
            "Epoch 49/100 (Explain): Test Acc (pseudo vs target) = 0.9073\n",
            "Epoch 50/100 (Explain): Test Acc (pseudo vs target) = 0.9967\n",
            "Epoch 51/100 (Explain): Test Acc (pseudo vs target) = 0.9970\n",
            "Epoch 52/100 (Explain): Test Acc (pseudo vs target) = 0.9979\n",
            "Epoch 53/100 (Explain): Test Acc (pseudo vs target) = 0.9949\n",
            "Epoch 54/100 (Explain): Test Acc (pseudo vs target) = 0.9975\n",
            "Epoch 55/100 (Explain): Test Acc (pseudo vs target) = 0.9919\n",
            "Epoch 56/100 (Explain): Test Acc (pseudo vs target) = 0.9840\n",
            "Epoch 57/100 (Explain): Test Acc (pseudo vs target) = 0.9949\n",
            "Epoch 58/100 (Explain): Test Acc (pseudo vs target) = 0.9941\n",
            "Epoch 59/100 (Explain): Test Acc (pseudo vs target) = 0.9851\n",
            "Epoch 60/100 (Explain): Test Acc (pseudo vs target) = 0.9908\n",
            "Epoch 61/100 (Explain): Test Acc (pseudo vs target) = 0.9944\n",
            "Epoch 62/100 (Explain): Test Acc (pseudo vs target) = 0.9944\n",
            "Epoch 63/100 (Explain): Test Acc (pseudo vs target) = 0.9880\n",
            "Epoch 64/100 (Explain): Test Acc (pseudo vs target) = 0.9939\n",
            "Epoch 65/100 (Explain): Test Acc (pseudo vs target) = 0.9957\n",
            "Epoch 66/100 (Explain): Test Acc (pseudo vs target) = 0.9913\n",
            "Epoch 67/100 (Explain): Test Acc (pseudo vs target) = 0.9886\n",
            "Epoch 68/100 (Explain): Test Acc (pseudo vs target) = 0.9956\n",
            "Epoch 69/100 (Explain): Test Acc (pseudo vs target) = 0.9825\n",
            "Epoch 70/100 (Explain): Test Acc (pseudo vs target) = 0.9964\n",
            "Epoch 71/100 (Explain): Test Acc (pseudo vs target) = 0.9913\n",
            "Epoch 72/100 (Explain): Test Acc (pseudo vs target) = 0.9890\n",
            "Epoch 73/100 (Explain): Test Acc (pseudo vs target) = 0.9944\n",
            "Epoch 74/100 (Explain): Test Acc (pseudo vs target) = 0.9971\n",
            "Epoch 75/100 (Explain): Test Acc (pseudo vs target) = 0.9933\n",
            "Epoch 76/100 (Explain): Test Acc (pseudo vs target) = 0.9912\n",
            "Epoch 77/100 (Explain): Test Acc (pseudo vs target) = 0.9907\n",
            "Epoch 78/100 (Explain): Test Acc (pseudo vs target) = 0.9961\n",
            "Epoch 79/100 (Explain): Test Acc (pseudo vs target) = 0.9890\n",
            "Epoch 80/100 (Explain): Test Acc (pseudo vs target) = 0.9911\n",
            "Epoch 81/100 (Explain): Test Acc (pseudo vs target) = 0.9726\n",
            "Epoch 82/100 (Explain): Test Acc (pseudo vs target) = 0.9822\n",
            "Epoch 83/100 (Explain): Test Acc (pseudo vs target) = 0.9923\n",
            "Epoch 84/100 (Explain): Test Acc (pseudo vs target) = 0.9445\n",
            "Epoch 85/100 (Explain): Test Acc (pseudo vs target) = 0.9882\n",
            "Epoch 86/100 (Explain): Test Acc (pseudo vs target) = 0.9542\n",
            "Epoch 87/100 (Explain): Test Acc (pseudo vs target) = 0.9779\n",
            "Epoch 88/100 (Explain): Test Acc (pseudo vs target) = 0.9775\n",
            "Epoch 89/100 (Explain): Test Acc (pseudo vs target) = 0.9793\n",
            "Epoch 90/100 (Explain): Test Acc (pseudo vs target) = 0.9494\n",
            "Epoch 91/100 (Explain): Test Acc (pseudo vs target) = 0.9695\n",
            "Epoch 92/100 (Explain): Test Acc (pseudo vs target) = 0.9598\n",
            "Epoch 93/100 (Explain): Test Acc (pseudo vs target) = 0.9736\n",
            "Epoch 94/100 (Explain): Test Acc (pseudo vs target) = 0.9721\n",
            "Epoch 95/100 (Explain): Test Acc (pseudo vs target) = 0.9779\n",
            "Epoch 96/100 (Explain): Test Acc (pseudo vs target) = 0.9826\n",
            "Epoch 97/100 (Explain): Test Acc (pseudo vs target) = 0.9812\n",
            "Epoch 98/100 (Explain): Test Acc (pseudo vs target) = 0.9874\n",
            "Epoch 99/100 (Explain): Test Acc (pseudo vs target) = 0.9763\n",
            "Epoch 100/100 (Explain): Test Acc (pseudo vs target) = 0.9918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import sqrtm\n",
        "import numpy as np\n",
        "import torch # Import torch\n",
        "\n",
        "def visualize_counterfactual(save_path, images_test, decoder, encoder, epoch):\n",
        "    \"\"\"\n",
        "    Selects a subset of test images and for each target class (0-9),\n",
        "    generates the counterfactual map and pseudo-image, then plots in a grid.\n",
        "    \"\"\"\n",
        "    plt_dir = os.path.join(save_path, \"plt\")\n",
        "    os.makedirs(plt_dir, exist_ok=True)\n",
        "    # Select 10 representative test images (could be random or fixed indices)\n",
        "    idxs = np.array([0,1,2,3,4,5,6,7,8,9])  # first 10 digits\n",
        "    fig_dat = []\n",
        "    for i in idxs:\n",
        "        img = images_test[i].astype(np.float32)\n",
        "        # Normalize each image to [0,1] for consistent display\n",
        "        img_min = img.min()\n",
        "        img_max = img.max()\n",
        "        if img_max > img_min:\n",
        "            img = (img - img_min) / (img_max - img_min)\n",
        "        else:\n",
        "            img = img # constant image\n",
        "        fig_dat.append(img)\n",
        "    fig_dat = np.stack(fig_dat, axis=0)  # shape (10,28,28)\n",
        "    code = np.eye(10, dtype=np.float32)  # identity (target codes)\n",
        "    # Build batch of input repeats: for each image, we will vary target from 0..9\n",
        "    total_input = []\n",
        "    total_codes = []\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            total_input.append(fig_dat[i])\n",
        "            total_codes.append(code[j])\n",
        "    total_input = np.stack(total_input, axis=0)  # (100,28,28)\n",
        "    total_codes = np.stack(total_codes, axis=0)  # (100,10)\n",
        "    total_input = np.expand_dims(total_input, axis=1)  # (100,1,28,28)\n",
        "    total_input_t = torch.tensor(total_input, dtype=torch.float32).to(device)\n",
        "    total_codes_t = torch.tensor(total_codes).to(device)\n",
        "    # Generate CF maps\n",
        "    with torch.no_grad():\n",
        "        enc1, enc2, enc3, enc4 = encoder(total_input_t)\n",
        "        # Ensure codemap is called with the correct input type and moved to CPU for numpy conversion\n",
        "        c1_np, c2_np, c3_np = codemap(total_codes_t.cpu().numpy())\n",
        "        c1 = torch.tensor(c1_np).to(device)\n",
        "        c2 = torch.tensor(c2_np).to(device)\n",
        "        c3 = torch.tensor(c3_np).to(device)\n",
        "        CFmap = decoder(enc1, enc2, enc3, enc4, c1, c2, c3)  # (100,1,28,28)\n",
        "        CFmap_np = CFmap.cpu().numpy().squeeze(1)\n",
        "        pseudo_np = total_input[:,0,:,:] + CFmap_np\n",
        "\n",
        "    # Plot grid: 10 rows (input index), each row shows: original, then 10 CF maps, then 10 pseudo-images\n",
        "    rows, cols = 10, 21\n",
        "    fig = plt.figure(figsize=(cols/2, rows/2))\n",
        "    for i in range(10):\n",
        "        # Original image in first column\n",
        "        ax_in = fig.add_subplot(rows, cols, i*cols + 1)\n",
        "        ax_in.imshow(fig_dat[i], cmap='gray'); ax_in.axis('off')\n",
        "        if i==0:\n",
        "            ax_in.set_title(\"Input\")\n",
        "        # Each target\n",
        "        for j in range(10):\n",
        "            ax_cf = fig.add_subplot(rows, cols, i*cols + 2 + j)\n",
        "            ax_cf.imshow(CFmap_np[i*10+j], cmap='gray'); ax_cf.axis('off')\n",
        "            ax_pseudo = fig.add_subplot(rows, cols, i*cols + 12 + j)\n",
        "            ax_pseudo.imshow(pseudo_np[i*10+j], cmap='gray'); ax_pseudo.axis('off')\n",
        "            if i==0:\n",
        "                ax_cf.set_title(f\"CF {j}\")\n",
        "                ax_pseudo.set_title(f\"Class {j}\")\n",
        "    plt.suptitle(f\"Counterfactual Maps - Epoch {epoch}\")\n",
        "    plt.savefig(os.path.join(plt_dir, f\"epoch{epoch}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def calculate_fid(act1, act2):\n",
        "    \"\"\"\n",
        "    Compute a simple FID-like score between two batches of images (arrays).\n",
        "    Inputs are expected to be (batch, height, width).\n",
        "    \"\"\"\n",
        "    # Reshape to (batch, height * width)\n",
        "    act1 = act1.reshape(act1.shape[0], -1).astype(np.float64)\n",
        "    act2 = act2.reshape(act2.shape[0], -1).astype(np.float64)\n",
        "\n",
        "    mu1 = np.mean(act1, axis=0)\n",
        "    mu2 = np.mean(act2, axis=0)\n",
        "    # Use bias=False for sample covariance\n",
        "    sigma1 = np.cov(act1, rowvar=False, bias=False)\n",
        "    sigma2 = np.cov(act2, rowvar=False, bias=False)\n",
        "\n",
        "    diff = np.sum((mu1 - mu2)**2) # Sum squared difference for vectors\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\n",
        "    # numerical stability\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "        # Optional: check if imaginary part is significant\n",
        "        # if np.max(np.abs(covmean.imag)) > 1e-6:\n",
        "        #     print(f\"Warning: Significant imaginary part in sqrtm result: {np.max(np.abs(covmean.imag))}\")\n",
        "\n",
        "    fid = diff + np.trace(sigma1 + sigma2 - 2*covmean)\n",
        "    return fid\n",
        "\n",
        "def estimate_fid(images_test, labels_test, decoder, encoder):\n",
        "    \"\"\"\n",
        "    Estimates FID-like scores for each class by comparing real vs. fake distributions.\n",
        "    For each class c, we pick samples of class c (real) and generate\n",
        "    pseudo-images of class c from other real images (fake), and compute FID.\n",
        "    \"\"\"\n",
        "    code = np.eye(10, dtype=np.float32)\n",
        "    min_samples_per_class = 800 # Ensure enough samples per class\n",
        "    fid_scores = {}\n",
        "\n",
        "    for num in range(10):\n",
        "        # 1. Get real images of class 'num'\n",
        "        real_class_idx = np.where(labels_test == num)[0]\n",
        "        rng = np.random.RandomState(seed=970304 + num) # Use different seed per class\n",
        "        # Shuffle and select a fixed number of samples\n",
        "        rng.shuffle(real_class_idx)\n",
        "        if len(real_class_idx) < min_samples_per_class:\n",
        "             print(f\"Warning: Not enough real samples for class {num}. Found {len(real_class_idx)}, need {min_samples_per_class}.\")\n",
        "             continue # Skip FID calculation for this class if not enough samples\n",
        "        real_images_class_num = images_test[real_class_idx[:min_samples_per_class]]\n",
        "\n",
        "        # Normalize real images (per image as done in separate_data)\n",
        "        real_norm = []\n",
        "        for img in real_images_class_num:\n",
        "            im = img.astype(np.float32) # Ensure float type\n",
        "            img_min = im.min()\n",
        "            img_max = im.max()\n",
        "            if img_max > img_min:\n",
        "                im = (im - img_min) / (img_max - img_min)\n",
        "            else:\n",
        "                im = im # constant image\n",
        "            real_norm.append(im)\n",
        "        real_norm = np.stack(real_norm, axis=0) # (min_samples_per_class, 28, 28)\n",
        "\n",
        "\n",
        "        # 2. Generate fake images (pseudo-images) targeting class 'num'\n",
        "        # Pick images from *other* classes as input, and set target to 'num'\n",
        "        other_classes_idx = np.where(labels_test != num)[0]\n",
        "        # Shuffle and select a fixed number of samples to generate pseudo-images from\n",
        "        rng.shuffle(other_classes_idx)\n",
        "        if len(other_classes_idx) < min_samples_per_class:\n",
        "             print(f\"Warning: Not enough samples from other classes to generate pseudo for class {num}. Found {len(other_classes_idx)}, need {min_samples_per_class}.\")\n",
        "             continue # Skip FID calculation for this class if not enough samples\n",
        "        input_images_for_pseudo = images_test[other_classes_idx[:min_samples_per_class]]\n",
        "\n",
        "        # Normalize input images for pseudo generation (using separate_data logic)\n",
        "        input_norm_pseudo = []\n",
        "        for img in input_images_for_pseudo:\n",
        "            im = img.astype(np.float32) # Ensure float type\n",
        "            img_min = im.min()\n",
        "            img_max = im.max()\n",
        "            if img_max > img_min:\n",
        "                im = (im - img_min) / (img_max - img_min)\n",
        "            else:\n",
        "                im = im # constant image\n",
        "            input_norm_pseudo.append(im)\n",
        "        input_norm_pseudo = np.stack(input_norm_pseudo, axis=0) # (min_samples_per_class, 28, 28)\n",
        "\n",
        "        # Add channel dimension and convert to tensor\n",
        "        input_norm_pseudo_t = torch.tensor(np.expand_dims(input_norm_pseudo, axis=1), dtype=torch.float32).to(device)\n",
        "\n",
        "        # Create target code for class 'num'\n",
        "        target_code_num = np.zeros((min_samples_per_class, 10), dtype=np.float32)\n",
        "        target_code_num[:, num] = 1.0\n",
        "        target_code_num_t = torch.tensor(target_code_num).to(device)\n",
        "\n",
        "        # Generate pseudo-images\n",
        "        decoder.eval() # Ensure decoder is in eval mode\n",
        "        encoder.eval() # Ensure encoder is in eval mode\n",
        "        with torch.no_grad():\n",
        "            enc1, enc2, enc3, enc4 = encoder(input_norm_pseudo_t)\n",
        "            c1_np, c2_np, c3_np = codemap(target_code_num_t.cpu().numpy())\n",
        "            c1 = torch.tensor(c1_np).to(device)\n",
        "            c2 = torch.tensor(c2_np).to(device)\n",
        "            c3 = torch.tensor(c3_np).to(device)\n",
        "            CFmap = decoder(enc1, enc2, enc3, enc4, c1, c2, c3)\n",
        "            pseudo = input_norm_pseudo_t[:,0,:,:] + CFmap.squeeze(1) # Pseudo is (batch, 28, 28)\n",
        "\n",
        "        fake_norm = pseudo.cpu().numpy() # (min_samples_per_class, 28, 28)\n",
        "\n",
        "\n",
        "        # 3. Compute FID between real and fake images of class 'num'\n",
        "        try:\n",
        "            fid = calculate_fid(real_norm, fake_norm)\n",
        "            fid_scores[num] = fid\n",
        "            print(f\"Class {num} FID (approx): {fid:.4f}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Could not compute FID for class {num}: {e}\")\n",
        "            # print shapes for debugging\n",
        "            # print(f\"Shapes: real_norm={real_norm.shape}, fake_norm={fake_norm.shape}\")\n",
        "            # print(f\"np.cov(real_norm, rowvar=False).shape={np.cov(real_norm.reshape(real_norm.shape[0], -1), rowvar=False, bias=False).shape}\")\n",
        "            # print(f\"np.cov(fake_norm, rowvar=False).shape={np.cov(fake_norm.reshape(fake_norm.shape[0], -1), rowvar=False, bias=False).shape}\")\n",
        "\n",
        "    # Optionally, print average FID\n",
        "    if fid_scores:\n",
        "        avg_fid = np.mean(list(fid_scores.values()))\n",
        "        print(f\"\\nAverage FID (approx) across classes: {avg_fid:.4f}\")"
      ],
      "metadata": {
        "id": "y16hOJQD79JA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_counterfactual(save_path, images_test, decoder, encoder, epoch=100)"
      ],
      "metadata": {
        "id": "4J_tTiWJ8nRD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate_fid(images_test, labels_test, decoder, encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbOP34yOBfJ6",
        "outputId": "57fb78c0-8ab1-47c2-d2f3-569570b06934"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 FID (approx): 40.3272\n",
            "Class 1 FID (approx): 47.6529\n",
            "Class 2 FID (approx): 29.9583\n",
            "Class 3 FID (approx): 27.9147\n",
            "Class 4 FID (approx): 26.8909\n",
            "Class 5 FID (approx): 18.6595\n",
            "Class 6 FID (approx): 36.4761\n",
            "Class 7 FID (approx): 36.3927\n",
            "Class 8 FID (approx): 22.2486\n",
            "Class 9 FID (approx): 26.4769\n",
            "\n",
            "Average FID (approx) across classes: 31.2998\n"
          ]
        }
      ]
    }
  ]
}
